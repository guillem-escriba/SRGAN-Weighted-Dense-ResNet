# -*- coding: utf-8 -*-
"""SRGAN_FP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10knGA-itrQNUFd-Gf2zt0s4bHMyfqkzi
"""

import scipy.io as sio
import numpy as np
from google.colab import drive
from PIL import Image
import os, sys
import cv2
import matplotlib.pyplot as plt
import datetime
import time
import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as tf
from skimage.metrics import peak_signal_noise_ratio, structural_similarity

drive.mount('/content/drive')
mat = 'dataset64to256.mat'
matfilePath = '/content/drive/My Drive/Curs 2022-2023/Deep Learning/FP/Mat/'+mat

data = sio.loadmat(matfilePath)
matrix = data['X']

for i in range(0,2):
  low_res_image = matrix[..., i]  # Get the first low-resolution image
  high_res_image = data['y'][..., i]  # Get the corresponding high-resolution image

  # Display the low-resolution image
  plt.imshow(low_res_image)
  plt.title('Low-Resolution Image')
  plt.axis('off')
  plt.show()

  # Display the high-resolution image
  plt.imshow(high_res_image)
  plt.title('High-Resolution Image')
  plt.axis('off')
  plt.show()

print(matrix.shape)

####################################
# 1- Dataset class
####################################

data_path= '/content/drive/My Drive/Curs 2022-2023/Deep Learning/FP/'
results_path ='/content/drive/My Drive/Curs 2022-2023/Deep Learning/FP/Results/'

class Data(torch.utils.data.Dataset):
      # Initialization method for the dataset
    def __init__(self,dataDir = data_path+'Mat/dataset.mat',transform = None):
        mat_loaded = sio.loadmat(dataDir) # Load the mat file containing the dataset
        self.data = mat_loaded['X']       # Store the low resolution images in a variable data
        self.label = mat_loaded['y']      # Store the high resolution images in a variable label
        self.transform = transform        # Determine a transform if needed

     # What to do to load a single item in the dataset ( read image)
    def __getitem__(self, index):
        data = self.data[:,:,:,index]             # Get the specified LR image
        data = Image.fromarray(data,mode='RGB')   # transform the LR image to array

        label = self.label[:,:,:,index]           # Get the specified HR image
        label = Image.fromarray(label,mode='RGB') # transform the HR image to array
        # Apply a trasnformaiton to the image if it is indicated in the initalizer
        if self.transform is not None :
            data = self.transform(data)
            label = self.transform(label)

        # return the image and the label as a tuple
        return data, label


    # Return the number of images
    def __len__(self):
        return self.data.shape[3]

tr = tf.Compose([
        tf.ToTensor(), # convert image to pytorch tensor [0..,1]
        ])

batch_size = 1
dataset = Data(data_path+'Mat/'+mat,tr)
train_loader = torch.utils.data.DataLoader(dataset=dataset,
                                               batch_size=batch_size,
                                               shuffle=False)
print(len(train_loader))

"""##Architectures

# Normal (Modified)

The following architecture is similar to the one that we have used at the start but with few changes. We have included some dropout layers with low probability to reduce the overfitting and prevent it. Also we have included 2 FC layers since the original one does not have any FC layer. It also includes an additional PReLU and some pooling layers, max pooling layers.
"""

#@title Normal Modified


# 2-Convolution + 2-Batch Normnalization + PReLU + ElementWise Sum for the generator
class residualBlock(nn.Module):
  def __init__(self,in_channels=64, k=3, n=64, s=1):
    super(residualBlock, self).__init__()

    self.conv1 = nn.Conv2d(in_channels, n, k, stride=s, padding=1)
    self.bn1 = nn.BatchNorm2d(n)
    self.conv2 = nn.Conv2d(n, n, k, stride=s, padding=1)
    self.bn2 = nn.BatchNorm2d(n)

    self.PReLU = nn.PReLU()

  def forward(self,x):
    result = self.PReLU(self.bn1(self.conv1(x)))
    return self.bn2(self.conv2(result)) + x

# Convolution + Batch Normalization + ElementWise Sum for the generator
class residualBlock2(nn.Module):
  def __init__(self,in_channels=64, k=3, n=64, s=1):
    super(residualBlock2, self).__init__()

    self.conv1 = nn.Conv2d(in_channels, n, k, stride=s, padding=1)
    self.bn1 = nn.BatchNorm2d(n)

  def forward(self ,x):
    return self.bn1(self.conv1(x))

# Convolution + PixelShuffler x2 + PReLU for the generator
class ConvPixelShufflerPReLU(nn.Module):
  def __init__(self,in_channels=64):
    super(ConvPixelShufflerPReLU, self).__init__()

    self.conv1 = nn.Conv2d(in_channels, in_channels * (2**2), 3, stride=1, padding=1)
    self.pixel_shuffle = nn.PixelShuffle(2) ##UpscaleFactor 2

    self.PReLU = nn.PReLU()

  def forward(self ,x):
    result = self.pixel_shuffle(self.conv1(x))
    return self.PReLU(result)

# Convolution + Batch Normalization + LReLU for the generator
class ConvBNLReLU(nn.Module):
  def __init__(self,in_channels=64, n=64, s=2):
    super(ConvBNLReLU, self).__init__()

    self.conv1 = nn.Conv2d(in_channels, n, 3, stride=s, padding=1)
    self.bn = nn.BatchNorm2d(n)
    self.dropout = nn.Dropout(0.1)
    self.LReLU = nn.LeakyReLU(0.2)

  def forward(self ,x):
    result = self.bn(self.conv1(x))
    return self.LReLU(self.dropout(result))

###### ENCODER & DECODER ######
# Compute model paramters
def compute_model_params(model):
  params = 0
  for p in model.parameters():
    params+= p.numel()

  return params

class Encoder(nn.Module):
  def __init__(self):
    super(Encoder, self).__init__()
    self.conv1 = nn.Conv2d(3, 64, 3, stride=1, padding=1)
    self.LReLU = nn.LeakyReLU(0.2)

    self.max_pool1 = nn.MaxPool2d(2,2) #128x128
    self.layer1 = ConvBNLReLU(in_channels=64, n=64, s=2) #64x64
    self.layer2 = ConvBNLReLU(in_channels=64, n=128, s=1)
    self.layer3 = ConvBNLReLU(in_channels=128, n=128, s=2) #32x32
    self.layer4 = ConvBNLReLU(in_channels=128, n=256, s=1)
    self.layer5 = ConvBNLReLU(in_channels=256, n=256, s=2) #16x16
    self.layer6 = ConvBNLReLU(in_channels=256, n=512, s=1)
    self.layer7 = ConvBNLReLU(in_channels=512, n=512, s=2) #8x8
    self.max_pool2 = nn.MaxPool2d(2,2) # 4x4
    self.fc1 = nn.Linear(512*4*4,256)
    self.PReLU = nn.PReLU(256)
    self.fc2 = nn.Linear(256,1)

  def forward(self,x):
    out = self.LReLU(self.conv1(x))
    out = self.max_pool1(out)
    out = self.layer1(out)
    out = self.layer2(out)
    out = self.layer3(out)
    out = self.layer4(out)
    out = self.layer5(out)
    out = self.layer6(out)
    out = self.layer7(out)
    out = self.max_pool2(out)
    out = out.reshape(out.size(0),-1)
    out = self.fc1(out)
    out = self.fc2(self.PReLU(out))
    return out

class Decoder(nn.Module):
  def __init__(self):
    super(Decoder, self).__init__()
    self.conv1 = nn.Conv2d(3, 64, 9, stride=1, padding=4)
    self.PReLU = nn.PReLU()

    self.resBlock5 = residualBlock()
    self.resBlock4 = residualBlock()
    self.resBlock3 = residualBlock()
    self.resBlock2 = residualBlock()
    self.resBlock1 = residualBlock()

    self.resBlock_2 = residualBlock2()

    self.pixelShuff2 = ConvPixelShufflerPReLU()
    self.pixelShuff1 = ConvPixelShufflerPReLU()

    self.conv2 = nn.Conv2d(64, 3, 9, stride=1, padding=4)

  def forward(self,x):

    out = self.PReLU(self.conv1(x))


    all_res = self.resBlock1(self.resBlock2(self.resBlock3(self.resBlock4(self.resBlock5(out)))))

    all_res_out = self.resBlock_2(all_res) + out
    shuff1 = self.pixelShuff1(all_res_out)
    shuff2 = self.pixelShuff2(shuff1)
    final_conv = self.conv2(shuff2)
    tt = (torch.tanh(final_conv) + 1) / 2
    return tt

###### DISCRIMINATOR & GENERATOR ######
class Discriminator(nn.Module):
  def __init__(self):
    super(Discriminator, self).__init__()
    # last fully connected layer acts as a a binary classifier
    self.classifier = Encoder()

  # Forward pass obtaining the discriminator probability
  def forward(self,x):
    out = self.classifier(x)
    # use sigmoid to get the real/fake image probability
    return torch.sigmoid(out)

class Generator(nn.Module):
  def __init__(self,in_features,base_channels=3):
    super(Generator, self).__init__()
    self.decoder = Decoder()

  # Generate an image from vector z
  def forward(self,z):
    return self.decoder(z)

generator_net = Generator(64)
discriminator_net = Discriminator()

gen_params = compute_model_params(generator_net)
print("Generator parameters: " + str(gen_params))

dis_params = compute_model_params(discriminator_net)
print("Discriminator parameters: " + str(dis_params))

print("Total amount of parameters: " + str(dis_params+gen_params))

"""# VGG IMPLEMENTATION with WEIGHTED DENSE RESIDUAL CONNECTIONS

This architecture changes drastically respect the previous one. First of all, the generator, instead of using simple residual connections, it uses Dense Residual Connections, that are essentially an upgraded version of normal residual connections by connecting each layer with any other layer.
But we go further including a variation of that, that essentialy adjusts the weight of each layer contribution taking into account where the residual connections come. We take this idea from the Momentum and the exponential weighted average. We have fixed the hyper parameter to 0.5^d(l) where d(l) is the distance between the origin of the residual connection and where it is connected.
Also we have changed the discriminator by reducing drastically the amount of parameters by using a pre-trained VGG19 where we take the first 16 CNN layers, this is done to reduce the amount of parameters to train without reducing the accuracy of feature detection of the discriminator. However, we still using some CNN layers and max_pool layers to let also the discriminator learn some parameters.
"""

#@title VGG IMPLEMENTATION with WEIGHTED DENSE RESIDUAL CONNECTIONS


# 2-Convolution + 2-Batch Normnalization + PReLU + ElementWise Sum for the generator
class residualBlock(nn.Module):
  def __init__(self,in_channels=64, k=3, n=64, s=1):
    super(residualBlock, self).__init__()

    self.conv1 = nn.Conv2d(in_channels, n, k, stride=s, padding=1)
    self.bn1 = nn.BatchNorm2d(n)
    self.conv2 = nn.Conv2d(n, n, k, stride=s, padding=1)
    self.bn2 = nn.BatchNorm2d(n)

    self.PReLU = nn.PReLU()

  def forward(self,x):
    result = self.PReLU(self.bn1(self.conv1(x)))
    return self.bn2(self.conv2(result)) + x

# Convolution + Batch Normalization + ElementWise Sum for the generator
class residualBlock2(nn.Module):
  def __init__(self,in_channels=64, k=3, n=64, s=1):
    super(residualBlock2, self).__init__()

    self.conv1 = nn.Conv2d(in_channels, n, k, stride=s, padding=1)
    self.bn1 = nn.BatchNorm2d(n)

  def forward(self ,x):
    return self.bn1(self.conv1(x))

# Convolution + PixelShuffler x2 + PReLU for the generator
class ConvPixelShufflerPReLU(nn.Module):
  def __init__(self,in_channels=64):
    super(ConvPixelShufflerPReLU, self).__init__()

    self.conv1 = nn.Conv2d(in_channels, in_channels * (2**2), 3, stride=1, padding=1)
    self.pixel_shuffle = nn.PixelShuffle(2) ##UpscaleFactor 2

    self.PReLU = nn.PReLU()

  def forward(self ,x):
    result = self.pixel_shuffle(self.conv1(x))
    return self.PReLU(result)

# Convolution + Batch Normalization + LReLU for the generator
class ConvBNLReLU(nn.Module):
  def __init__(self,in_channels=64, n=64, s=2):
    super(ConvBNLReLU, self).__init__()

    self.conv1 = nn.Conv2d(in_channels, n, 3, stride=s, padding=1)
    self.bn = nn.BatchNorm2d(n)
    self.dropout = nn.Dropout(0.1)
    self.LReLU = nn.LeakyReLU(0.2)

  def forward(self ,x):
    result = self.bn(self.conv1(x))
    return self.LReLU(self.dropout(result))

###### ENCODER & DECODER ######
# Compute model paramters
def compute_model_params(model):
  params = 0
  for p in model.parameters():
    params+= p.numel()

  return params

class Encoder(nn.Module):
  def __init__(self):
    super(Encoder, self).__init__()


    self.layer1 = ConvBNLReLU(in_channels=512, n=512, s=2) #8x8
    self.max_pool1 = nn.MaxPool2d(2,2) #4x4
    self.layer2 = ConvBNLReLU(in_channels=512, n=512, s=2) #2x2
    #self.max_pool2 = nn.MaxPool2d(2,2) #1x1

    self.fc1 = nn.Linear(512*2*2,256)
    self.PReLU = nn.PReLU(256)
    self.fc2 = nn.Linear(256,1)

  def forward(self,x):
    out = self.layer1(x)
    out = self.max_pool1(out)
    out = self.layer2(out)
    #out = self.max_pool2(out)
    out = out.reshape(out.size(0),-1)
    out = self.fc1(out)
    out = self.fc2(self.PReLU(out))
    return out

class Decoder(nn.Module):
  def __init__(self):
    super(Decoder, self).__init__()
    self.conv1 = nn.Conv2d(3, 64, 9, stride=1, padding=4)
    self.PReLU = nn.PReLU()

    self.resBlock1 = residualBlock()
    self.resBlock2 = residualBlock()
    self.resBlock3 = residualBlock()
    self.resBlock4 = residualBlock()
    self.resBlock5 = residualBlock()

    self.final_resBlock = residualBlock2()

    self.pixelShuff1 = ConvPixelShufflerPReLU()
    self.pixelShuff2 = ConvPixelShufflerPReLU()

    self.conv2 = nn.Conv2d(64, 3, 9, stride=1, padding=4)

  def forward(self,x):

    out = self.PReLU(self.conv1(x))

    b=0.5 # Hyper parameter that weights the connections
    # WEIGHTED DENSE RESIDUAL CONNECTIONS
    res1 = self.resBlock1(out)+((b)**1)*out
    res2 = self.resBlock2(res1)+((b)**1)*res1 + ((b)**2)*out
    res3 = self.resBlock3(res2)+((b)**1)*res2 + ((b)**2)*res1 + ((b)**3)*out
    res4 = self.resBlock4(res3)+((b)**1)*res3 + ((b)**2)*res2 + ((b)**3)*res1 + ((b)**4)*out
    res5 = self.resBlock5(res4)+((b)**1)*res4 + ((b)**2)*res3 + ((b)**3)*res2 + ((b)**4)*res1 + ((b)**5)*out

    f_res = self.final_resBlock(res5)+((b)**1)*out

    shuff1 = self.pixelShuff1(f_res)
    shuff2 = self.pixelShuff2(shuff1)

    final_conv = self.conv2(shuff2)

    tt = (torch.tanh(final_conv) + 1) / 2
    return tt

###### DISCRIMINATOR & GENERATOR ######
class Discriminator(nn.Module):
  def __init__(self):
    super(Discriminator, self).__init__()
    # last fully connected layer acts as a a binary classifier
    self.classifier = Encoder()

  # Forward pass obtaining the discriminator probability
  def forward(self,x):
    out = self.classifier(x)
    # use sigmoid to get the real/fake image probability
    return torch.sigmoid(out)

class Generator(nn.Module):
  def __init__(self,in_features,base_channels=3):
    super(Generator, self).__init__()
    self.decoder = Decoder()

  # Generate an image from vector z
  def forward(self,z):
    return self.decoder(z)

generator_net = Generator(64)
discriminator_net = Discriminator()

gen_params = compute_model_params(generator_net)
print("Generator parameters: " + str(gen_params))

dis_params = compute_model_params(discriminator_net)
print("Discriminator parameters: " + str(dis_params))

print("Total amount of parameters: " + str(dis_params+gen_params))

"""# TRAINING SRGAN

To train our model, we ask the **Generator** to generate a Super Resolution image from a Low Resolution one, and pass it to the **Discriminator** together with the High Resolution image, so that it can decide wich one is the Real.

Our perceptual loss function consist of a **Content Loss** which computes the pixel-wise MSE loss between both images + an **Adversarial Loss**  based  on  the  probabilities  of  the  discriminator.
"""

from torchvision.models import vgg19

VGG19 = vgg19(pretrained = True)
truncated_VGG19 = nn.Sequential(*list(VGG19.features.children())[:(35 + 1)]) # First 16 layers of VGG19 (without the FC ones)

# GAN Train function. We have a generator and discriminator models and their respective optimizers.
def train_GAN(gen, disc, use_VGG, VGG,  train_loader, optimizer_gen, optim_disc,
              num_epochs=10, model_name='SRGAN_new_batch1_e30_x4.ckpt', device='cpu'):
    gen = gen.to(device)
    gen.train() # Set the generator in train mode
    disc = disc.to(device)
    disc.train() # Set the discriminator in train mode
    if(use_VGG):
      VGG = VGG.to(device)


    total_step = len(train_loader)
    disc_loss_list = []
    gen_loss_list = []

    msel = nn.MSELoss()


    # Iterate over epochs
    for epoch in range(num_epochs):
        # Iterate the dataset
        disc_loss_avg = 0
        gen_loss_avg = 0
        nBatches = 0
        psnr=0
        ssim=0

        for i, (LR_images, HR_images) in enumerate(train_loader):

            # Get batch of samples and labels
            #print(real_images[0,:,:,:].shape)
            LR_images = LR_images.to(device)
            HR_images = HR_images.to(device)
            n_images = LR_images.shape[0]





            # Generate SR images
            SR_images = gen.forward(LR_images)

            if(use_VGG): #if we are using VGG for training
              VGG_HR_images = VGG(HR_images) # This step can be precomputed
              VGG_SR_images = VGG(SR_images)
              #print(SR_images.shape)
              #print(LR_images.shape)
              #print(HR_images.shape)

              # Use the discriminator to obtain the probabilties for real and generate imee
              prob_HR = disc(VGG_HR_images).mean()
              prob_SR = disc(VGG_SR_images).mean()
            else:

              # Use the discriminator to obtain the probabilties for real and generate imee
              prob_HR = disc(HR_images).mean()
              prob_SR = disc(SR_images).mean()

            if(i==0):
              print("Prob of HR being HR:",prob_HR.cpu().item())
              print("Prob of SR being HR:",prob_SR.cpu().item())

            # Discriminator loss
            #disc_loss = 1 - prob_HR + prob_SR

            disc_loss = prob_SR-prob_HR # Wasserstein Loss

            #disc_loss = -(torch.log(prob_HR)+torch.log(1-prob_SR)).mean() # CE


            # Generator loss
            content_loss = msel(SR_images, HR_images)
            #adversarial_loss = -torch.log(prob_SR).mean()
            adversarial_loss = -prob_SR # Wasserstein Loss
            gen_loss = content_loss + 0.001*adversarial_loss

            # We are going to update the discriminator and generator parameters alternatively at each iteration

            if(epoch%4>2 or epoch == 0):
              # Optimize generator
              # Backward and optimize

              if(i==0): print("Updating GENERATOR")
              optimizer_gen.zero_grad()
              gen_loss.backward() # Necessary to not erase intermediate variables needed for computing disc_loss gradient
              optimizer_gen.step()
              #update_generator = False
            else:
              # Optimize discriminator
              # Backward and optimize
              if(i==0):print("Updating DISCRIMINATOR")
              optimizer_disc.zero_grad()
              disc_loss.backward()
              optimizer_disc.step()
              #update_generator = True


            disc_loss_avg += disc_loss.cpu().item()
            gen_loss_avg += gen_loss.cpu().item()

            psnr += peak_signal_noise_ratio(HR_images.cpu().detach().numpy(), SR_images.cpu().detach().numpy(),
                                           data_range=255.)
            #ssim += structural_similarity(HR_images.cpu().detach().numpy(), SR_images.cpu().detach().numpy(),
                                            #data_range=255.)


            nBatches+=1
            n_batches = len(train_loader)
            if (i+1) % int(n_batches*0.4) == 0:
                print ('Epoch [{}/{}], Step [{}/{}], Gen. Loss: {:.4f}, Disc Loss: {:.4f}, PSNR: {:.2f}, SSIM: {:.4f}'
                       .format(epoch+1, num_epochs, i+1, total_step, gen_loss_avg / nBatches, disc_loss_avg / nBatches, psnr / nBatches, ssim / nBatches))
        print ('Epoch [{}/{}], Step [{}/{}], Gen. Loss: {:.4f}, Disc Loss: {:.4f}, PSNR: {:.2f}, SSIM: {:.4f}'
                       .format(epoch+1, num_epochs, i+1, total_step, gen_loss_avg / nBatches, disc_loss_avg / nBatches, psnr / nBatches, ssim / nBatches))


        # For every 10 epochs: Plot the LR-HR-SR images of the training resoults
        if (epoch+1) % 2 == 0:
          image = LR_images.cpu()[0,:,:,:]
          RGB_img = cv2.cvtColor(image.permute(1,2,0).squeeze().numpy(), cv2.COLOR_BGR2RGB)
          plt.imshow(RGB_img)
          plt.show()

          image1 = HR_images.cpu()[0,:,:,:]
          RGB_img1 = cv2.cvtColor(image1.permute(1,2,0).squeeze().numpy(), cv2.COLOR_BGR2RGB)
          plt.imshow(RGB_img1)
          plt.show()

          image2 = SR_images.cpu()[0,:,:,:]
          RGB_img2 = cv2.cvtColor(image2.permute(1,2,0).squeeze().detach().numpy(), cv2.COLOR_BGR2RGB)
          plt.imshow(RGB_img2)
          plt.show()

        # Save model
        disc_loss_list.append(disc_loss_avg / nBatches)
        gen_loss_list.append(gen_loss_avg / nBatches)
        torch.save(gen.state_dict(), results_path+ '/' + model_name)

    # Plot the LR-HR-SR images of the las training resoults
    image = LR_images.cpu()[0,:,:,:]
    plt.imshow(image.permute(1,2,0).squeeze().detach().numpy())
    plt.show()

    image1 = HR_images.cpu()[0,:,:,:]
    plt.imshow(image1.permute(1,2,0).squeeze().detach().numpy())
    plt.show()

    image2 = SR_images.cpu()[0,:,:,:]
    plt.imshow(image2.permute(1,2,0).squeeze().detach().numpy())
    plt.show()
    return disc_loss_list, gen_loss_list

# Define Geneartor and Discriminator networks

generator_net = Generator(64)
discriminator_net = Discriminator()

gen_params = compute_model_params(generator_net)
print("Generator parameters: " + str(gen_params))

dis_params = compute_model_params(discriminator_net)
print("Discriminator parameters: " + str(dis_params))

print("Total amount of parameters: " + str(dis_params+gen_params))

#Initialize indepdent optimizer for both networks
learning_rate = .0005
optimizer_gen = torch.optim.Adam(generator_net.parameters(),lr = 0.0009, weight_decay=1e-5)
optimizer_disc = torch.optim.Adam(discriminator_net.parameters(),lr = 0.0003, weight_decay=1e-5)

# Train the GAN
epochs = 100
now = datetime.datetime.now()
name = 'WeightedDenseResCons_VGG_BS_'+str(batch_size)+'_E'+str(epochs)+'x4_'+str(now.hour)+str(now.minute)
model_name = name +'.ckpt'

print(name)
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
disc_loss_list, gen_loss_list = train_GAN(generator_net,discriminator_net,True,truncated_VGG19, train_loader, optimizer_gen, optimizer_disc,
                      num_epochs=epochs, model_name=model_name, device=device)

import matplotlib.pyplot as plt

# plot the loss list
plt.figure(figsize=(10, 6))
plt.plot(disc_loss_list)
plt.title('Discriminator Loss across epochs')
plt.xlabel('Epochs')
plt.ylabel('Discriminator Loss')
plt.grid(True)

plt.savefig('/content/drive/My Drive/Curs 2022-2023/Deep Learning/FP/Results/Plots/disc_loss_'+name+'.png', dpi=300, bbox_inches='tight')
plt.show()

# plot the loss list
plt.figure(figsize=(10, 6))
plt.plot(gen_loss_list)
plt.title('Generator Loss across epochs')
plt.xlabel('Epochs')
plt.ylabel('Generator Loss')
plt.grid(True)

plt.savefig('/content/drive/My Drive/Curs 2022-2023/Deep Learning/FP/Results/Plots/gen_loss_'+name+'.png', dpi=300, bbox_inches='tight')
plt.show()

class DataTest(torch.utils.data.Dataset):
      # Initialization method for the dataset
    def __init__(self,dataDir = data_path+'Mat/datasetTest.mat',transform = None):
        mat_loaded = sio.loadmat(dataDir)   # Load the mat file containing the dataset
        self.data = mat_loaded['X']         # Store the low resolution images in a variable data
        self.label = mat_loaded['y']      # Store the high resolution images in a variable label
        self.transform = transform          # Determine a transform if needed

     # What to do to load a single item in the dataset ( read image)
    def __getitem__(self, index):
        data = self.data[:,:,:,index]             # Get the specified LR image
        #data = cv2.cvtColor(data, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB
        data = Image.fromarray(data,mode='RGB')   # transform the LR image to array

        label = self.label[:,:,:,index]           # Get the specified HR image
        label = Image.fromarray(label,mode='RGB') # transform the HR image to array
        # Apply a trasnformaiton to the image if it is indicated in the initalizer
        if self.transform is not None :
            data = self.transform(data)
            label = self.transform(label)

        # return the image and the label
        return data, label

    # Return the number of images
    def __len__(self):
        return self.data.shape[3]

tr = tf.Compose([
        tf.ToTensor(), # convert image to pytorch tensor [0..,1]
        ])

# Load the Test Dataset from th e specified .mat
datasetTest = DataTest(data_path+'Mat/datasetTest.mat',tr)
test_loader = torch.utils.data.DataLoader(dataset=datasetTest,
                                               batch_size=1,
                                               shuffle=False)

# Mini-batch images and labels.
images = next(iter(test_loader))
inp = images[0]
lbl = images[1]
image = inp[0,:,:,:]
image2 = lbl[0,:,:,:]
plt.imshow(image.permute(1, 2, 0).squeeze().numpy())
plt.show()
plt.imshow(image2.permute(1, 2, 0).squeeze().numpy())
plt.show()

from skimage.metrics import peak_signal_noise_ratio, structural_similarity
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

# Load generator
gan_gen = Generator(64)
gan_gen.load_state_dict(torch.load(results_path+model_name))
gan_gen.eval() # Put in eval model
gan_gen = gan_gen.to(device)
rgb_weights = torch.FloatTensor([65.481, 128.553, 24.966]).to(device)

psnr=0
ssim=0

# From every Image in the Test Dataset, we generate a SR image.
for i, (LR_images, HR_images) in enumerate(test_loader):
    LR_images = LR_images.to(device)
    HR_images = HR_images.to(device)

    # Generate SR images
    SR_images = gan_gen.forward(LR_images)

    # Plot Low Resolution Image (original)
    LR = LR_images.cpu()[0, :, :, :]
    RGB_LR = LR.permute(1, 2, 0).squeeze().detach().numpy()
    RGB_LR = (RGB_LR * 255).astype(np.uint8)
    RGB_LR = cv2.cvtColor(RGB_LR, cv2.COLOR_RGB2BGR)
    #cv2.imwrite(results_path + "TestImages/LR" + str(i) + "BS1_e30.png", RGB_LR)
    plt.imshow(cv2.cvtColor(RGB_LR, cv2.COLOR_BGR2RGB))
    plt.show()

    # Plot Super Resolution Image (Fake)
    SR = SR_images.cpu()[0, :, :, :]
    RGB_SR = SR.permute(1, 2, 0).squeeze().detach().numpy()
    RGB_SR = (RGB_SR * 255).astype(np.uint8)
    RGB_SR = cv2.cvtColor(RGB_SR, cv2.COLOR_RGB2BGR)
    cv2.imwrite(results_path + "TestImages/SR" + str(i) + name + ".png", RGB_SR)
    plt.imshow(cv2.cvtColor(RGB_SR, cv2.COLOR_BGR2RGB))
    plt.show()

    HR = HR_images.cpu()[0, :, :, :]
    RGB_HR = HR.permute(1, 2, 0).squeeze().detach().numpy()
    RGB_HR = (RGB_HR * 255).astype(np.uint8)
    RGB_HR = cv2.cvtColor(RGB_HR, cv2.COLOR_RGB2BGR)
    plt.imshow(cv2.cvtColor(RGB_HR, cv2.COLOR_BGR2RGB))
    plt.show()

    # Convert SR images
    SR_images = torch.matmul(255. * SR_images.permute(0, 2, 3, 1)[:, 4:-4, 4:-4, :], rgb_weights) / 255. + 16.
    SR_images = ((SR_images + 1.) / 2.).squeeze(0)

    # Convert HR images
    HR_images = torch.matmul(255. * HR_images.permute(0, 2, 3, 1)[:, 4:-4, 4:-4, :], rgb_weights) / 255. + 16.
    HR_images = ((HR_images + 1.) / 2.).squeeze(0)

    psnr += peak_signal_noise_ratio(HR_images.cpu().detach().numpy(), SR_images.cpu().detach().numpy(),
                                           data_range=255.)
    ssim += structural_similarity(HR_images.cpu().detach().numpy(), SR_images.cpu().detach().numpy(),
                                         data_range=255.)

print("Average PSNR: " + str(psnr/100))
print("Average SSIM: " + str(ssim/100))